{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEmiuZL3xwLe2PQvMCww6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danilobml/pytorch-networks/blob/main/basic_text_classifier_neural_network_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ol_jz3l0NP-p"
      },
      "outputs": [],
      "source": [
        "# Sentiment analysis and classification NN.\n",
        "\n",
        "# Text pre-processing (using nltk)\n",
        "# import\n",
        "import nltk\n",
        "\n",
        "# Download its libraries (here all of them)\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the file from gihthub repo, using numpy and pandas and put it into a dataframe:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/sharmaroshan/Restaurant-Reviews-Analysis/refs/heads/master/Restaurant_Reviews.tsv', delimiter='\\t', quoting=3)\n",
        "dataset.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TESAs7eVUJOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing task imports:\n",
        "\n",
        "# To remove stopwords (recurring words that add no meaning) using nltk:\n",
        "from nltk.corpus import stopwords\n",
        "# To use stemming - derive the root form of words (ex: running and runner -> run)\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# Python regex to remove commas, points and other symbols:\n",
        "import re\n",
        "\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "oIOO2m54U1sX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the dataset:\n",
        "dataset.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HDyf04PDWd6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through all words, removing stopwords and using stemming,\n",
        "# to create a corpus of clean text:\n",
        "\n",
        "corpus = []\n",
        "\n",
        "for i in range(0, 1000):\n",
        "  # symbol replacing of each review\n",
        "  customer_review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "  # lower case and separation of words by space:\n",
        "  customer_review = customer_review.lower()\n",
        "  customer_review = customer_review.split()\n",
        "  # Clan review - apply stemming and remove stopwords:\n",
        "  clean_review = [ps.stem(word) for word in customer_review if not word in set(stopwords.words('english'))]\n",
        "  clean_review = ' '.join(clean_review)\n",
        "  corpus.append(clean_review)"
      ],
      "metadata": {
        "id": "eR1hQ9U7WlPw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the sentences to numeric format using TFIDF vectorizer from scikitlearn:\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Specify how many words (max_features) you want and the number of times they\n",
        "# have to be repeated (min_df) to count, max_df removes words that are too frequent\n",
        "# 0.6 means remove if it appears in 60% or more of all texts:\n",
        "vectorizer = TfidfVectorizer(max_features=1500, min_df=3, max_df=0.6)\n",
        "# Convert corpus to a numeric array:\n",
        "X = vectorizer.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "JpHuk8WQYyFe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check sample:\n",
        "X[0]\n",
        "\n",
        "# For relevant words, you will get a value non-zero (TF-IDF):\n",
        "\n",
        "# TF (Term Frequency) -> repetition of the words/total words in document\n",
        "\n",
        "# IDF (Inverse Document Frequency) -> tests how relevant the word is:\n",
        "\n",
        "# df(t) = N(t)\n",
        "# where\n",
        "# df(t) = Document frequency of a term t\n",
        "# N(t) = Number of documents containing the term t\n",
        "# N = Total number of documents\n",
        "# IDF(t) = log(N/df(t))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2TursOgUZWrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dependent variable y, which will carry the labels. For that, get\n",
        "# all the rows in the second column, convert to a numpy array:\n",
        "\n",
        "y = dataset.iloc[:, 1].values"
      ],
      "metadata": {
        "id": "bO44mmNRasyj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset in training (80%) and test (20%) sets, using sklearn:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "metadata": {
        "id": "R908lufgcKFE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the pytorch Neural Network:\n",
        "# imports:\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "mkDe_OsSc2Wh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert training and test data to (float) Tensors:\n",
        "Xtrain_ = torch.from_numpy(X_train).float()\n",
        "Xtest_ = torch.from_numpy(X_test).float()\n",
        "\n",
        "ytrain_ = torch.from_numpy(y_train)\n",
        "ytest_ = torch.from_numpy(y_test)"
      ],
      "metadata": {
        "id": "bXaA10Z3d0DN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to check tensors shape:\n",
        "Xtrain_.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWAFoIrpenYj",
        "outputId": "8801a86a-a057-4e3d-d05b-d5946acdd581"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([800, 467]), (800,))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The number to the right of the total is the total of vectrized word.\n",
        "# It will be the input_size of the NN\n",
        "\n",
        "input_size = 467\n",
        "\n",
        "# Output size is two (sentiment positive or negative)\n",
        "output_size = 2\n",
        "\n",
        "# Hidden size can be different numbers to be tried:\n",
        "hidden_size = 500"
      ],
      "metadata": {
        "id": "J4ai7rGVfL-A"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Neural Network class with two hidden layers:\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    # define layers, using Linear:\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  # define the forward method -> calls the layers, passing them through ReLU\n",
        "  # (rectified linear unit function -> the most commonly used activation function\n",
        "  # in deep learning models. The function returns 0 if it receives any negative\n",
        "  # input, but for any positive value x it returns that value back):\n",
        "  def forward(self, X):\n",
        "    X = torch.relu((self.fc1(X)))\n",
        "    X = torch.relu((self.fc2(X)))\n",
        "    X = self.fc3(X)\n",
        "    # run through log_softmax -> function that computes the output and gradient:\n",
        "    return F.log_softmax(X, dim=1)\n",
        "\n",
        "# Instantiate model:\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "iyBcvgEAftEb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and loss function:\n",
        "import torch.optim as optim\n",
        "\n",
        "# For optimizer, we use Adam, with model-parameters and learn rate:\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# For loss function NLLLoss -> negative log likelihood loss.\n",
        "# It is useful to train a classification problems with an\n",
        "# unbalanced training set:\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "LQ71OCQ-iQx7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define epochs and train Neural Network:\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # first call optimizer with zero_grad -> Resets the gradients of optimized tensors:\n",
        "  optimizer.zero_grad()\n",
        "  # define predictions:\n",
        "  Ypred = model(Xtrain_)\n",
        "  # calculate loss -> deviation from expected values (labels):\n",
        "  loss = loss_fn(Ypred, ytrain_)\n",
        "  # Backpropagation -> calculates and stores the gradients for each model parameter\n",
        "  loss.backward()\n",
        "  # Optimization (parameter update)\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch {epoch} - loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y4o5SlojPR-",
        "outputId": "085a0176-5521-4712-f244-7ec049215c69"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - loss: 0.6933143734931946\n",
            "Epoch 10 - loss: 0.047478772699832916\n",
            "Epoch 20 - loss: 0.03230816125869751\n",
            "Epoch 30 - loss: 0.029457466676831245\n",
            "Epoch 40 - loss: 0.028391627594828606\n",
            "Epoch 50 - loss: 0.028234241530299187\n",
            "Epoch 60 - loss: 0.028121326118707657\n",
            "Epoch 70 - loss: 0.028086772188544273\n",
            "Epoch 80 - loss: 0.02810979075729847\n",
            "Epoch 90 - loss: 0.02864963747560978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model for future use:\n",
        "# TODO - later"
      ],
      "metadata": {
        "id": "mOw0Rkx1jVNZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model:\n",
        "\n",
        "# write a text with an evaluation inside a list:\n",
        "sample = ['The fish was really good!']\n",
        "# Transforme it into a numeric array:\n",
        "sample = vectorizer.transform(sample).toarray()\n",
        "# Convert to Tensor:\n",
        "sample = torch.from_numpy(sample).float()\n",
        "\n",
        "# Apply model to predict -> if the first element in the tensor is higher than\n",
        "# the first, it's positive:\n",
        "sentiment = model(sample)\n",
        "sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we0nPuVnlPRj",
        "outputId": "75802b07-1088-4b39-daa9-04fc208ff50b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-22.1356,   0.0000]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or, to simplifiy reading:\n",
        "if sentiment[0][1] > sentiment[0][0]:\n",
        "  print('positive')\n",
        "else:\n",
        "  print('negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXh022Y_luvi",
        "outputId": "6bee6d42-3399-4b25-8548-bfb644901145"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A second run, now with text not related to restaurant reviews:\n",
        "\n",
        "sample2 = ['Trump is a bad politician.']\n",
        "\n",
        "sample2 = vectorizer.transform(sample2).toarray()\n",
        "sample2 = torch.from_numpy(sample2).float()\n",
        "\n",
        "sentiment2 = model(sample2)\n",
        "\n",
        "if sentiment2[0][1] > sentiment2[0][0]:\n",
        "  print('positive')\n",
        "else:\n",
        "  print('negative')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4usRUXcmySE",
        "outputId": "e8217f11-e53e-4018-855a-e776d19054de"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    }
  ]
}